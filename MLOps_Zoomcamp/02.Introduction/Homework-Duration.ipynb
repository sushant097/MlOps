{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312ac093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3b8004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-07-14 17:22:53--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-01.parquet\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.216.129.123\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.216.129.123|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2022-07-14 17:22:54 ERROR 403: Forbidden.\n",
      "\n",
      "--2022-07-14 17:22:54--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-02.parquet\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.216.129.123\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.216.129.123|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2022-07-14 17:22:55 ERROR 403: Forbidden.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "# DOWNLOADING THE DATASET: UNCOMMENT BELOW:\n",
    "# !wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-01.parquet\n",
    "# !wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458eff71",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: './fhv_tripdata_2021-01.parquet\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14740/2357019591.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./fhv_tripdata_2021-01.parquet\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m     return impl.read(\n\u001b[0m\u001b[0;32m    496\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"split_blocks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# type: ignore[assignment]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n\u001b[0m\u001b[0;32m    233\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"filesystem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m# fsspec resources can also point to directories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         handles = get_handle(\n\u001b[0m\u001b[0;32m    102\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: './fhv_tripdata_2021-01.parquet\"'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('./fhv_tripdata_2021-01.parquet\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f6a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00fc8c8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14740/1509735071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d11d41",
   "metadata": {},
   "source": [
    "Q. Read the data for January. How many records are there?\n",
    "        \n",
    "        Ans: 1154112\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e610db7b",
   "metadata": {},
   "source": [
    "### Q2. Computing duration\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duration\"] = df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"]\n",
    "df[\"duration\"] = df[\"duration\"].apply(lambda x: x.total_seconds() / 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duration.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968cdca",
   "metadata": {},
   "source": [
    "What's the average trip duration in January?\n",
    "\n",
    "        Ans: 19.16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e29d38",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Check the distribution of the duration variable. There are some outliers.\n",
    "\n",
    "Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "How many records did you drop?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7212025a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14740/1829348131.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Before: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m \u001b[1;33m<=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"After: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No. of records were droped:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Before: \", len(df))\n",
    "prev = df\n",
    "df = df[(df.duration >= 1) & (df.duration <=60)]\n",
    "print(\"After: \", len(df))\n",
    "print(\"No. of records were droped:\", len(prev) - len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270628ad",
   "metadata": {},
   "source": [
    "### Q3. Missing values\n",
    "The features we'll use for our model are the pickup and dropoff location IDs.\n",
    "\n",
    "But they have a lot of missing values there. Let's replace them with \"-1\".\n",
    "\n",
    "What's the fractions of missing values for the pickup location ID? I.e. fraction of \"-1\"s after you filled the NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4ad74",
   "metadata": {},
   "source": [
    "        ANS: 83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377a817",
   "metadata": {},
   "source": [
    "### Q4. One-hot encoding\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "1. Turn the dataframe into a list of dictionaries\n",
    "3. Fit a dictionary vectorizer\n",
    "4. Get a feature matrix from it\n",
    "    \n",
    "    What's the dimensionality of this matrix? (The number of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing one hot encoding:\n",
    "train_dicts = df[categorical].to_dict(orient=\"records\") # initialize dict\n",
    "dict_v = DictVectorizer()\n",
    "X_train = dict_v.fit_transform(train_dicts)\n",
    "y_train = df['duartion'].values\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f4e198",
   "metadata": {},
   "source": [
    "    Ans: 525"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f429a",
   "metadata": {},
   "source": [
    "### Q5. Training a model\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "* Train a plain linear regression model with default parameters\n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Linear Regression\n",
    "lr = LinearRegression()                                        # Intialization\n",
    "lr.fit(X_train, y_train)                                       # Training model\n",
    "y_pred = lr.predict(X_train)                                   # Initializing prediction\n",
    "rmse_error = mean_squared_error(y_train, y_pred, squared=False) # calculating mse\n",
    "print(rmse_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a14f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of prediction\n",
    "sns.distplot(y_train, label=\"actual\")\n",
    "sns.distplot(y_pred, label=\"prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05c6f3",
   "metadata": {},
   "source": [
    "    Ans: 10.52"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152604c",
   "metadata": {},
   "source": [
    "### Q6. Evaluating the model\n",
    "Now let's apply this model to the validation dataset (Feb 2021).\n",
    "\n",
    "What's the RMSE on validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f631d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        df = pd.read_csv(filename)\n",
    "        df[\"lpep_dropoff_datetime\"] =  pd.to_datetime(df[\"lpep_dropoff_datetime\"])\n",
    "        df[\"lpep_pickup_datetime\"] = pd.to_datetime(df[\"lpep_pickup_datetime\"])\n",
    "    elif filename.endswith(\".parquet\"):\n",
    "        df = pd.read_parquet(filename)\n",
    "    else:\n",
    "        print(\"Only .csv | parquet files are allowed\")\n",
    "        return\n",
    "    df[\"duration\"] = df[\"lpep_dropoff_datetime\"] - df[\"lpep_pickup_datetime\"]\n",
    "    df[\"duration\"] = df.duration.apply(lambda x: x.total_seconds() / 60)    # convert into minutes\n",
    "    df = df[(df.duration >=1) & (df.duration <= 60)]\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b88027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalizing train and validation DataFrame:\n",
    "df_train = read_dataframe(\"./fhv_tripdata_2021-01.parquet\")\n",
    "df_val = read_dataframe(\"./fhv_tripdata_2021-02.parquet\")\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize one hot encoding in a function:\n",
    "def one_hot_encoding(df_train, df_val, categorical):\n",
    "    '''\n",
    "    categorical: List of categorical col names\n",
    "    numerical: List of numerical col names\n",
    "    '''\n",
    "    dict_v = DictVectorizer()\n",
    "    train_dicts = df_train[categorical].to_dict(orient=\"records\") # initialize dict\n",
    "    X_train = dict_v.fit_transform(train_dicts)\n",
    "    val_dicts = df_val[categorical ].to_dict(orient=\"records\")\n",
    "    X_val = dict_v.transform(val_dicts)\n",
    "    target = \"duration\"\n",
    "    y_train = df_train[target].values\n",
    "    y_val = df_val[target].values\n",
    "    return dict_v, X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ee1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\"PU_DO\"]\n",
    "dv, X_train, X_val, y_train, y_val = one_hot_encoding(df_train, df_val, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87126133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_val)\n",
    "print(mean_squared_error(y_val, y_pred, squared=False)) # print RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb146e",
   "metadata": {},
   "source": [
    "    Ans: 11.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of prediction\n",
    "sns.distplot(y_val, label=\"actual\")\n",
    "sns.distplot(y_pred, label=\"prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab4c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
